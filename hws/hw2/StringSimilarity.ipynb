{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![spelling-mistakessss-sss-ss-sss-s.png](attachment:spelling-mistakessss-sss-ss-sss-s.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import codecs\n",
    "from typing import List, Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import codecs\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import editdistance\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See Data, Feel Data, Preprocess Data [1 балл]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_path = Path(\"your/path/to/words2.txt\")\n",
    "broken_texts_path = Path(\"your/path/to/broken_texts.csv\")\n",
    "correct_texts_path = Path(\"your/path/to/derived.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(broken_texts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>не обнаруживается различий в общем объеме серо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>интегумент ( от - покрывало , покров ) - терми...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22 июня 2013 года решениме большинстав судей ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>в 1987 mi выпустила альбом all the best !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>путевая машинная станция 79 была создана 16 фе...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text\n",
       "0   0  не обнаруживается различий в общем объеме серо...\n",
       "1   1  интегумент ( от - покрывало , покров ) - терми...\n",
       "2   2  22 июня 2013 года решениме большинстав судей ,...\n",
       "3   3          в 1987 mi выпустила альбом all the best !\n",
       "4   4  путевая машинная станция 79 была создана 16 фе..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = # TODO: Sorted list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert words_list[::20000] == ['!',\n",
    "                               'daewoo',\n",
    "                               'агенобарб',\n",
    "                               'биотопа',\n",
    "                               'восхитительный',\n",
    "                               'дебальцево',\n",
    "                               'зафрахтованные',\n",
    "                               'километровой',\n",
    "                               'лесными',\n",
    "                               'московщина',\n",
    "                               'овдовевшего',\n",
    "                               'пионер-11',\n",
    "                               'провозглашавшая',\n",
    "                               'рыжиков',\n",
    "                               'спокоен',\n",
    "                               'тэйна',\n",
    "                               'хэй']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(words_list) == 339275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(df: pd.DataFrame) -> str:\n",
    "    # TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract it a little bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "\n",
    "class Speller:\n",
    "    \n",
    "    @abstractmethod\n",
    "    def fit(self, words: List[str], **kwargs):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, data: str, **kwargs) -> str:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rectifier:\n",
    "    \n",
    "    @abstractmethod\n",
    "    def rectify(self, data: List[str]) -> List[str]:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mesure_metric(gt: List[str], broken: List[str], corrected: List[str]) -> float:\n",
    "    all_tokens = 0\n",
    "    correct = 0\n",
    "    for gt_sentence, broken_sentence, corrected_sentence in zip(gt, broken, corrected):\n",
    "        for gt_token, broken_token, corrected_token in zip(gt_sentence.split(), broken_sentence.split(), corrected_sentence.split()):\n",
    "            if gt_token != broken_token:\n",
    "                all_tokens += 1\n",
    "                if gt_token == corrected_token:\n",
    "                    correct += 1\n",
    "    return correct / all_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rectifier [1 балл]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rectifier(Rectifier):\n",
    "    \n",
    "    def __init__(self, words: Set[str], speller: Speller):\n",
    "        pass\n",
    "    \n",
    "    def rectify(self, data: List[str]) -> List[str]:\n",
    "        corrected = []\n",
    "        \n",
    "        #TODO\n",
    "        \n",
    "        return corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Speller [2 балла]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSpeller(Speller):\n",
    "    \"Inspired by Petr Norvig Spellchecker\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._letters = 'абвгдеёжзиклмнопрстуфхцчшщъыьэюя'\n",
    "    \n",
    "    def fit(self, words: List[str], **kwargs):\n",
    "        self._words = set(words)\n",
    "        return self\n",
    "    \n",
    "    @lru_cache(maxsize=10000)\n",
    "    def predict(self, word: str) -> str:\n",
    "        suggests = self._get_candidates(word)\n",
    "        \n",
    "        closest_word = word\n",
    "        minimal_distance = 1000\n",
    "        for suggest in suggests:\n",
    "            # TODO\n",
    "            closest_word = suggest\n",
    "        return closest_word\n",
    "    \n",
    "    def _get_candidates(self, word: str) -> Set[str]:\n",
    "        candidates = set()\n",
    "        # TODO\n",
    "        return candidates\n",
    "    \n",
    "    def _get_edits(self, word: str) -> Set[str]:\n",
    "        splits     =  # держать -> [(д, ержать), (де, ржать), ...]\n",
    "        deletes    = # все варианты удалений одной буквы\n",
    "        transposes = # все варианты транспонирования\n",
    "        replaces   = # все варианты замен\n",
    "        inserts    = # все варианты вставок\n",
    "        return set(deletes + transposes + replaces + inserts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rectifier = Rectifier(set(words_list), SimpleSpeller().fit(words_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_text = rectifier.rectify(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = pd.read_csv(correct_texts_path)[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert mesure_metric(gt, texts, corrected_text) > 0.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate Speller [2 балла]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap(word):\n",
    "    return u\" %s \" % word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntermediateSpeller(Speller):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.neighbours = 5\n",
    "        self.vectorizer = CountVectorizer(analyzer=\"char\", ngram_range=(1, 2), binary=True)\n",
    "        self.searcher = NearestNeighbors(algorithm=\"auto\", n_neighbors=self.neighbours, radius=3)\n",
    "    \n",
    "    def fit(self, words: List[str], **kwargs):\n",
    "        self.words = np.array(words)\n",
    "\n",
    "        encoded_words = ...\n",
    "        #TODO\n",
    "\n",
    "        return self\n",
    "    \n",
    "    @lru_cache(maxsize=10000)\n",
    "    def predict(self, word: str) -> str:\n",
    "        #TODO\n",
    "\n",
    "        closest_word = word\n",
    "        minimal_distance = 1000\n",
    "\n",
    "        suggests = ...\n",
    "\n",
    "        for suggest in suggests:\n",
    "            #TODO\n",
    "            closest_word = unwrapped_suggest\n",
    "        return closest_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_words_list = list(map(lambda x : wrap(x), words_list))\n",
    "rectifier = Rectifier(set(words_list), IntermediateSpeller().fit(wrapped_words_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_text = rectifier.rectify(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = pd.read_csv(correct_texts_path)[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert mesure_metric(gt, texts, corrected_text) > 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Good Speller [2 балла]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert mesure_metric(gt, texts, corrected_text) > 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Amazing Speller [2 балла]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert mesure_metric(gt, texts, corrected_text) > 0.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
